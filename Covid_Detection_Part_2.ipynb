{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CV_Project_Part2.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyPYCybGoY0sLp9JTv3tb1Dh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"mCcUMHzk0_Q3"},"source":["### Data Sources"]},{"cell_type":"markdown","metadata":{"id":"AqT0ak1F0-ty"},"source":["##### 1. https://www.kaggle.com/plameneduardo/sarscov2-ctscan-dataset (Brazil) - .PNG\n","##### 2. https://www.kaggle.com/luisblanche/covidct (Mixed) - .JPG"]},{"cell_type":"markdown","metadata":{"id":"cafuDMOTohdQ"},"source":["Training the Model on Brazil's Data and testing its performance on Mixed Data was giving poor results."]},{"cell_type":"markdown","metadata":{"id":"wX5HkWWsoveB"},"source":["Combining both data sets for training the model"]},{"cell_type":"markdown","metadata":{"id":"U4smg_Bj06XO"},"source":["### Mounting Google Drive"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v7P14bpe0NpZ","executionInfo":{"status":"ok","timestamp":1622187522099,"user_tz":-330,"elapsed":619,"user":{"displayName":"Abhijeet Upadhyay (MT19AIE201)","photoUrl":"","userId":"12194432948742235723"}},"outputId":"daba5829-1865-4305-cbd2-0860a0a9313b"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CpRMUduL0Vzf"},"source":["### Loading required Libraries"]},{"cell_type":"code","metadata":{"id":"4iKMZBds2iaK"},"source":["import warnings\n","warnings.filterwarnings('ignore')\n","\n","import os\n","import glob\n","import random\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","palette = sns.color_palette(\"bright\", 10)\n","sns.set(rc={'figure.figsize':(12,8)})\n","\n","from skimage.transform import resize\n","from skimage import feature\n","import cv2\n","from google.colab.patches import cv2_imshow\n","import PIL\n","from PIL import Image\n","from PIL import ImageEnhance\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n","\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch import nn\n","from torchvision import models\n","from torchsummary import summary\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader, TensorDataset\n","from torch import autograd\n","import torch.nn.functional as F\n","from torchvision.datasets import ImageFolder\n","from torchvision.utils import make_grid\n","from torch.utils.data import random_split\n","from torchvision import datasets\n","from torchvision import transforms\n","from torch.utils.data.sampler import SubsetRandomSampler\n","from torch.autograd import Variable"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B7vLLOar4BT7"},"source":["### Function to Measure the Model Performance"]},{"cell_type":"code","metadata":{"id":"B45m7SWx3vZs"},"source":["def accuracy_metrics(y, y_pred, y_prob):\n","    results = confusion_matrix(y, y_pred) \n","    print('Confusion Matrix :')\n","    print(results) \n","    print('Accuracy :  ', round(accuracy_score(y, y_pred), 2))\n","    print('Precision : ', round(precision_score(y, y_pred), 2))\n","    print('Recall :    ', round(recall_score(y, y_pred), 2))\n","    print('FI Score :  ', round(f1_score(y, y_pred), 2))\n","    print('AUC :       ', round(roc_auc_score(y, y_prob), 2))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dXQB0q0MwYm_"},"source":["### Display Sample Images"]},{"cell_type":"code","metadata":{"id":"Wr6WyWEBO4kR"},"source":["#function to enhance images\n","def enhance_contrast(image, contrast = 1.5):\n","    image = Image.fromarray(image)\n","    enh_con = ImageEnhance.Contrast(image)\n","    image_contrasted = enh_con.enhance(contrast)\n","    cr_img = np.array(image_contrasted)\n","    return cr_img\n","\n","def enhance_brightness(image, brightness = 1.5):\n","    image = Image.fromarray(image)\n","    enh_bri = ImageEnhance.Brightness(image)\n","    image_brigthened = enh_bri.enhance(brightness)\n","    cr_img = np.array(image_brigthened)\n","    return cr_img"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c9dEuabbu79K"},"source":["### Data Size"]},{"cell_type":"code","metadata":{"id":"ab0HINJLnF_N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622187522732,"user_tz":-330,"elapsed":11,"user":{"displayName":"Abhijeet Upadhyay (MT19AIE201)","photoUrl":"","userId":"12194432948742235723"}},"outputId":"8182adf4-77a0-4f04-90b7-17b6e02c42f5"},"source":["combined_path = \"/content/drive/MyDrive/MTECH AI/Semester 3/Computer Vision/CV_Project/Data/Combined_Data/\"\n","data_size_combined = len(glob.glob(combined_path + \"*/*\"))\n","\n","print(data_size_combined)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2968\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pRdmuO4Jxnmv"},"source":["### Data Loader"]},{"cell_type":"code","metadata":{"id":"zf5MPyWJKWGc"},"source":["#custom dataset\n","class CustomDataset(Dataset):\n","    def __init__(self, path, img_dim = (224, 224), enhance = False, enhance_fun = enhance_contrast):\n","        self.imgs_path = path\n","        file_list = glob.glob(self.imgs_path + \"*\")\n","        self.data = []\n","        for class_path in file_list:\n","            class_name = class_path.split(\"/\")[-1]\n","            for img_path in glob.glob(class_path + \"*/*\"):\n","                self.data.append([img_path, class_name])\n","        self.class_map = {\"Non_Covid\" : 0, \"Covid\": 1}\n","        self.img_dim = img_dim\n","        self.enhance = enhance\n","        self.enhance_func = enhance_fun\n","    def __len__(self):\n","        return len(self.data)\n","    def __getitem__(self, idx):\n","        img_path, class_name = self.data[idx]\n","        img = cv2.imread(img_path)\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        if self.enhance:\n","           img = self.enhance_func(img)  \n","        img = cv2.resize(img, self.img_dim)\n","        class_id = self.class_map[class_name]\n","        img_tensor = torch.from_numpy(img/255.)\n","        img_tensor = img_tensor.permute(2, 0, 1)\n","        class_id = torch.tensor([class_id])\n","        return img_tensor, class_id.squeeze()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MW9RAcozyww-"},"source":["There are 2 different data sources. 1st source has CT Scan images in .PNG format from Brazil whereas, 2nd data source has images from all over the world in .JPG format. 1st Data will be divided into train & validation while 2nd data will be used as test data."]},{"cell_type":"code","metadata":{"id":"Yo_V0s2tchHg"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XOjl3cYQiALD"},"source":["We will check if any of image enhancement methods are able to boost the performance or not!"]},{"cell_type":"markdown","metadata":{"id":"hjKBFWl2zXH2"},"source":["### 1. Baseline CNN on Different Data Sources for Training & Testing without Image Enhancement"]},{"cell_type":"markdown","metadata":{"id":"27AraBnGxvka"},"source":["#### Loading Train, Test & Validation Data"]},{"cell_type":"code","metadata":{"id":"erqevHM4qNgY"},"source":["#data utilitiesa\n","random_state = 100\n","batch_size = 16\n","validation_split = 0.15\n","indices = list(range(data_size_combined))\n","split = int(np.floor(validation_split * data_size_combined))\n","\n","#indices for training and validation splits:\n","np.random.seed(random_state)\n","np.random.shuffle(indices)\n","\n","train_indices, val_indices, test_indices = indices[2*split:], indices[:split], indices[split:2*split]\n","\n","# Creating PT data samplers and loaders:\n","train_sampler = SubsetRandomSampler(train_indices)\n","val_sampler = SubsetRandomSampler(val_indices)\n","test_sampler = SubsetRandomSampler(test_indices)\n","\n","dataset = CustomDataset(path = combined_path, enhance = False)\n","train_loader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, sampler = train_sampler, num_workers = 2)\n","val_loader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, sampler = val_sampler, num_workers = 2)\n","test_loader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, sampler = test_sampler, num_workers = 2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AruVKaJvDODm"},"source":["#### CNN Model Structure"]},{"cell_type":"code","metadata":{"id":"0DU6veK5Vnjm"},"source":["#cnn model class\n","def call_bn(bn, x):\n","    return bn(x)\n","\n","class CNN(nn.Module):\n","    def __init__(self, in_channels = 3):\n","        super(CNN, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels = in_channels, out_channels = 64, kernel_size = 3)\n","        self.conv2 = nn.Conv2d(64, 64, kernel_size = 3)\n","        self.conv3 = nn.Conv2d(64, 96, kernel_size = 3)\n","        self.conv4 = nn.Conv2d(96, 96, kernel_size = 3)\n","        self.conv5 = nn.Conv2d(96, 128, kernel_size = 3)\n","        self.conv6 = nn.Conv2d(128, 128, kernel_size = 3)\n","        self.fc1 = nn.Linear(128 * 5 * 5, 512)\n","        self.fc2 = nn.Linear(512, 64)\n","        self.fc3 = nn.Linear(64, 2)\n","        self.pool = nn.MaxPool2d(kernel_size = 2)\n","        self.dropout = nn.Dropout(0.5)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.bn2 = nn.BatchNorm2d(64)\n","        self.bn3 = nn.BatchNorm2d(96)\n","        self.bn4 = nn.BatchNorm2d(96)\n","        self.bn5 = nn.BatchNorm2d(128)\n","        self.bn6 = nn.BatchNorm2d(128)\n","        self.bn7 = nn.BatchNorm1d(512)\n","        self.bn8 = nn.BatchNorm1d(64)\n","\n","    def forward(self, x, verbose = False):\n","        x = self.conv1(x)\n","        x = call_bn(self.bn1, x)\n","        x = F.relu(x)\n","        x = self.conv2(x)\n","        x = call_bn(self.bn2, x)\n","        x = F.relu(x)\n","        x = self.pool(x)\n","        x = self.dropout(x)\n","\n","        x = self.conv3(x)\n","        x = call_bn(self.bn3, x)\n","        x = F.relu(x)\n","        x = self.pool(x)\n","        x = self.dropout(x)\n","        x = self.conv4(x)\n","        x = call_bn(self.bn4, x)\n","        x = F.relu(x)\n","        x = self.pool(x)\n","        x = self.dropout(x)\n","\n","        x = self.conv5(x)\n","        x = call_bn(self.bn5, x)\n","        x = F.relu(x)\n","        x = self.pool(x)\n","        x = self.dropout(x)\n","        x = self.conv6(x)\n","        x = call_bn(self.bn6, x)\n","        x = F.relu(x)\n","        x = self.pool(x)\n","        x = self.dropout(x)\n","      \n","        x = x.view(-1, 128 * 5 * 5)\n","        \n","        x = self.fc1(x)\n","        x = call_bn(self.bn7, x)\n","        x = F.relu(x)\n","        x = self.dropout(x)\n","        x = self.fc2(x)\n","        x = call_bn(self.bn8, x)\n","        x = F.relu(x)\n","        x = self.dropout(x)\n","        x = self.fc3(x)\n","        \n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zLduZgEpHL_H","executionInfo":{"status":"ok","timestamp":1622187523648,"user_tz":-330,"elapsed":11,"user":{"displayName":"Abhijeet Upadhyay (MT19AIE201)","photoUrl":"","userId":"12194432948742235723"}},"outputId":"ed474e46-5a94-4778-ca0c-2e919b8905ac"},"source":["#initialise model\n","model = CNN()\n","\n","#set device to be cude\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","#model structure\n","print(model)\n","summary(model, (3, 224, 224))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["CNN(\n","  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n","  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n","  (conv3): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1))\n","  (conv4): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1))\n","  (conv5): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1))\n","  (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n","  (fc1): Linear(in_features=3200, out_features=512, bias=True)\n","  (fc2): Linear(in_features=512, out_features=64, bias=True)\n","  (fc3): Linear(in_features=64, out_features=2, bias=True)\n","  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (bn4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (bn5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (bn6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (bn7): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (bn8): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",")\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 222, 222]           1,792\n","       BatchNorm2d-2         [-1, 64, 222, 222]             128\n","            Conv2d-3         [-1, 64, 220, 220]          36,928\n","       BatchNorm2d-4         [-1, 64, 220, 220]             128\n","         MaxPool2d-5         [-1, 64, 110, 110]               0\n","           Dropout-6         [-1, 64, 110, 110]               0\n","            Conv2d-7         [-1, 96, 108, 108]          55,392\n","       BatchNorm2d-8         [-1, 96, 108, 108]             192\n","         MaxPool2d-9           [-1, 96, 54, 54]               0\n","          Dropout-10           [-1, 96, 54, 54]               0\n","           Conv2d-11           [-1, 96, 52, 52]          83,040\n","      BatchNorm2d-12           [-1, 96, 52, 52]             192\n","        MaxPool2d-13           [-1, 96, 26, 26]               0\n","          Dropout-14           [-1, 96, 26, 26]               0\n","           Conv2d-15          [-1, 128, 24, 24]         110,720\n","      BatchNorm2d-16          [-1, 128, 24, 24]             256\n","        MaxPool2d-17          [-1, 128, 12, 12]               0\n","          Dropout-18          [-1, 128, 12, 12]               0\n","           Conv2d-19          [-1, 128, 10, 10]         147,584\n","      BatchNorm2d-20          [-1, 128, 10, 10]             256\n","        MaxPool2d-21            [-1, 128, 5, 5]               0\n","          Dropout-22            [-1, 128, 5, 5]               0\n","           Linear-23                  [-1, 512]       1,638,912\n","      BatchNorm1d-24                  [-1, 512]           1,024\n","          Dropout-25                  [-1, 512]               0\n","           Linear-26                   [-1, 64]          32,832\n","      BatchNorm1d-27                   [-1, 64]             128\n","          Dropout-28                   [-1, 64]               0\n","           Linear-29                    [-1, 2]             130\n","================================================================\n","Total params: 2,109,634\n","Trainable params: 2,109,634\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 135.18\n","Params size (MB): 8.05\n","Estimated Total Size (MB): 143.80\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6AFGdIHwDUf5"},"source":["#### Loss & Optimizer"]},{"cell_type":"code","metadata":{"id":"2QDAgE3dzXA0"},"source":["#loss & optimizer\n","criterion = nn.CrossEntropyLoss().to(device)\n","optimizer = optim.Adamax(model.parameters(), weight_decay = 1e-6)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gdd4Q5_Z0MMI"},"source":["#### Model Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"erqOziPGlUHt","executionInfo":{"status":"ok","timestamp":1622188259874,"user_tz":-330,"elapsed":736233,"user":{"displayName":"Abhijeet Upadhyay (MT19AIE201)","photoUrl":"","userId":"12194432948742235723"}},"outputId":"8feb0552-8a0c-47f7-bfda-009d1b7e84aa"},"source":["#training\n","start_epoch = 0\n","epochs = 50\n","\n","best_val_acc = 0\n","\n","print('Started Training ... !!!')\n","\n","for epoch in range(start_epoch, epochs + start_epoch):\n","\n","    train_loss = 0.0\n","    train_correct = 0.0\n","    items = 0\n","\n","    model.train()\n","    for data in train_loader:\n","        # get the inputs\n","        inputs, labels = data[0], data[1]\n","\n","        items += len(inputs)\n","        \n","        #change inputs to cuda type\n","        inputs = inputs.to(device = device, dtype = torch.float)\n","        labels = labels.to(device = device)\n","\n","        #wrap them in Variable\n","        inputs, labels = Variable(inputs), Variable(labels)\n","\n","        #zero the parameter gradients\n","        optimizer.zero_grad()\n","        \n","        #forward + backward + optimize\n","        pred_train = model(inputs)                                     #prediction\n","        pred_train_probs = torch.softmax(pred_train, dim = 1)          #predicted probability\n","        loss_t = criterion(pred_train_probs, labels)                   #calculate loss\n","        \n","        _, pred_train_labels = torch.max(pred_train_probs, 1)          #assigning class label to prediction\n","        train_correct += (pred_train_labels == labels).sum().item()    #count correct preditions  \n","\n","        loss_t.backward()                                              #backpropogate\n","        optimizer.step()                                               #update weights\n","\n","        train_loss += loss_t.item()                                    #update loss\n","\n","    #normalizing the loss & accuracy by the total number of train batches\n","    train_loss /= len(train_loader)\n","    train_acc =  (train_correct * 100) / items\n","\n","\n","    #MODEL VALIDATION\n","    with torch.no_grad():\n","         model.eval()\n","         val_loss = 0.0\n","         val_correct = 0.0\n","         val_items = 0\n","         \n","         for data_val in val_loader:    #get the inputs\n","             val_inputs, val_labels = data_val[0], data_val[1]\n","\n","             val_items += len(val_inputs)\n","\n","             #converting input and labels to cuda \n","             val_inputs = val_inputs.to(device = device, dtype = torch.float)\n","             val_labels = val_labels.to(device = device)\n","\n","             #wrap them in Variable\n","             val_inputs, val_labels = Variable(val_inputs), Variable(val_labels)\n","\n","             pred_val = model(val_inputs)                                   #prediction\n","             pred_val_probs = torch.softmax(pred_val, dim = 1)              #predicted probability\n","             loss_v = criterion(pred_val_probs, val_labels)                 #calculate loss\n","             \n","             _, pred_val_labels = torch.max(pred_val_probs, 1)              #assigning class label to prediction\n","             val_correct += (pred_val_labels == val_labels).sum().item()    #count correct predictions\n","\n","             val_loss += loss_v.item()                                      #update loss\n","          \n","         #normalizing the loss by the total number of val batches\n","         val_loss /= len(val_loader)\n","         val_acc =  (val_correct * 100) / val_items\n","\n","         #save the best model\n","         if val_acc > best_val_acc:\n","            torch.save(model.state_dict(), '/content/drive/MyDrive/MTECH AI/Semester 3/Computer Vision/CV_Project/Saved_Models/cnn_ct_raw_combined.pth')   #save model\n","            best_val_acc = val_acc         #change best val accuracy\n","        \n","    print(f'Epoch {epoch + 1}: | Train Loss: {train_loss:.5f} | Train Accuracy: {train_acc:.3f} % | Validation Loss: {val_loss:.5f} | Validation Accuracy: {val_acc:.3f} %')\n","\n","print('Finished Training ... !!!')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Started Training ... !!!\n","Epoch 1: | Train Loss: 0.62945 | Train Accuracy: 64.966 % | Validation Loss: 0.83290 | Validation Accuracy: 47.640 %\n","Epoch 2: | Train Loss: 0.56746 | Train Accuracy: 74.302 % | Validation Loss: 0.82050 | Validation Accuracy: 47.640 %\n","Epoch 3: | Train Loss: 0.53166 | Train Accuracy: 78.296 % | Validation Loss: 0.82012 | Validation Accuracy: 47.640 %\n","Epoch 4: | Train Loss: 0.52230 | Train Accuracy: 78.345 % | Validation Loss: 0.53055 | Validation Accuracy: 80.000 %\n","Epoch 5: | Train Loss: 0.51092 | Train Accuracy: 80.221 % | Validation Loss: 0.53322 | Validation Accuracy: 79.551 %\n","Epoch 6: | Train Loss: 0.49368 | Train Accuracy: 80.943 % | Validation Loss: 0.69618 | Validation Accuracy: 56.629 %\n","Epoch 7: | Train Loss: 0.49170 | Train Accuracy: 81.424 % | Validation Loss: 0.49460 | Validation Accuracy: 82.022 %\n","Epoch 8: | Train Loss: 0.48708 | Train Accuracy: 81.569 % | Validation Loss: 0.48966 | Validation Accuracy: 81.573 %\n","Epoch 9: | Train Loss: 0.48966 | Train Accuracy: 81.521 % | Validation Loss: 0.47687 | Validation Accuracy: 83.146 %\n","Epoch 10: | Train Loss: 0.48209 | Train Accuracy: 82.387 % | Validation Loss: 0.48873 | Validation Accuracy: 81.348 %\n","Epoch 11: | Train Loss: 0.46978 | Train Accuracy: 83.879 % | Validation Loss: 0.48912 | Validation Accuracy: 80.899 %\n","Epoch 12: | Train Loss: 0.45440 | Train Accuracy: 85.804 % | Validation Loss: 0.47138 | Validation Accuracy: 82.921 %\n","Epoch 13: | Train Loss: 0.46741 | Train Accuracy: 84.071 % | Validation Loss: 0.51356 | Validation Accuracy: 78.876 %\n","Epoch 14: | Train Loss: 0.46061 | Train Accuracy: 84.552 % | Validation Loss: 0.50236 | Validation Accuracy: 78.876 %\n","Epoch 15: | Train Loss: 0.46333 | Train Accuracy: 84.793 % | Validation Loss: 0.56408 | Validation Accuracy: 72.584 %\n","Epoch 16: | Train Loss: 0.45676 | Train Accuracy: 85.322 % | Validation Loss: 0.50898 | Validation Accuracy: 79.775 %\n","Epoch 17: | Train Loss: 0.45348 | Train Accuracy: 85.322 % | Validation Loss: 0.50038 | Validation Accuracy: 80.225 %\n","Epoch 18: | Train Loss: 0.44710 | Train Accuracy: 86.574 % | Validation Loss: 0.45980 | Validation Accuracy: 84.494 %\n","Epoch 19: | Train Loss: 0.45117 | Train Accuracy: 85.611 % | Validation Loss: 0.52791 | Validation Accuracy: 77.528 %\n","Epoch 20: | Train Loss: 0.44114 | Train Accuracy: 86.862 % | Validation Loss: 0.46000 | Validation Accuracy: 83.820 %\n","Epoch 21: | Train Loss: 0.44685 | Train Accuracy: 85.996 % | Validation Loss: 0.45108 | Validation Accuracy: 85.843 %\n","Epoch 22: | Train Loss: 0.44824 | Train Accuracy: 85.996 % | Validation Loss: 0.47374 | Validation Accuracy: 83.146 %\n","Epoch 23: | Train Loss: 0.44828 | Train Accuracy: 86.381 % | Validation Loss: 0.43666 | Validation Accuracy: 86.742 %\n","Epoch 24: | Train Loss: 0.44219 | Train Accuracy: 86.814 % | Validation Loss: 0.42786 | Validation Accuracy: 87.865 %\n","Epoch 25: | Train Loss: 0.43649 | Train Accuracy: 87.488 % | Validation Loss: 0.53476 | Validation Accuracy: 76.180 %\n","Epoch 26: | Train Loss: 0.43479 | Train Accuracy: 87.777 % | Validation Loss: 0.46678 | Validation Accuracy: 84.045 %\n","Epoch 27: | Train Loss: 0.44786 | Train Accuracy: 85.563 % | Validation Loss: 0.48708 | Validation Accuracy: 81.348 %\n","Epoch 28: | Train Loss: 0.43019 | Train Accuracy: 88.017 % | Validation Loss: 0.50158 | Validation Accuracy: 80.899 %\n","Epoch 29: | Train Loss: 0.42663 | Train Accuracy: 88.402 % | Validation Loss: 0.48089 | Validation Accuracy: 82.472 %\n","Epoch 30: | Train Loss: 0.43931 | Train Accuracy: 86.718 % | Validation Loss: 0.58032 | Validation Accuracy: 71.910 %\n","Epoch 31: | Train Loss: 0.43704 | Train Accuracy: 87.247 % | Validation Loss: 0.44603 | Validation Accuracy: 86.067 %\n","Epoch 32: | Train Loss: 0.44163 | Train Accuracy: 86.718 % | Validation Loss: 0.42978 | Validation Accuracy: 88.090 %\n","Epoch 33: | Train Loss: 0.41780 | Train Accuracy: 89.509 % | Validation Loss: 0.45820 | Validation Accuracy: 84.270 %\n","Epoch 34: | Train Loss: 0.41995 | Train Accuracy: 88.932 % | Validation Loss: 0.42955 | Validation Accuracy: 87.416 %\n","Epoch 35: | Train Loss: 0.42991 | Train Accuracy: 87.921 % | Validation Loss: 0.45939 | Validation Accuracy: 84.944 %\n","Epoch 36: | Train Loss: 0.43141 | Train Accuracy: 87.536 % | Validation Loss: 0.45423 | Validation Accuracy: 84.719 %\n","Epoch 37: | Train Loss: 0.42190 | Train Accuracy: 89.076 % | Validation Loss: 0.47591 | Validation Accuracy: 83.371 %\n","Epoch 38: | Train Loss: 0.42272 | Train Accuracy: 88.643 % | Validation Loss: 0.44620 | Validation Accuracy: 85.618 %\n","Epoch 39: | Train Loss: 0.42630 | Train Accuracy: 88.114 % | Validation Loss: 0.43809 | Validation Accuracy: 86.517 %\n","Epoch 40: | Train Loss: 0.42373 | Train Accuracy: 88.691 % | Validation Loss: 0.42083 | Validation Accuracy: 88.764 %\n","Epoch 41: | Train Loss: 0.41749 | Train Accuracy: 89.076 % | Validation Loss: 0.43269 | Validation Accuracy: 86.966 %\n","Epoch 42: | Train Loss: 0.41984 | Train Accuracy: 88.691 % | Validation Loss: 0.41654 | Validation Accuracy: 89.438 %\n","Epoch 43: | Train Loss: 0.41413 | Train Accuracy: 89.172 % | Validation Loss: 0.42343 | Validation Accuracy: 87.865 %\n","Epoch 44: | Train Loss: 0.41149 | Train Accuracy: 89.990 % | Validation Loss: 0.41032 | Validation Accuracy: 89.888 %\n","Epoch 45: | Train Loss: 0.41738 | Train Accuracy: 89.269 % | Validation Loss: 0.47487 | Validation Accuracy: 82.472 %\n","Epoch 46: | Train Loss: 0.40701 | Train Accuracy: 90.568 % | Validation Loss: 0.48769 | Validation Accuracy: 81.573 %\n","Epoch 47: | Train Loss: 0.42328 | Train Accuracy: 88.547 % | Validation Loss: 0.42731 | Validation Accuracy: 87.640 %\n","Epoch 48: | Train Loss: 0.41326 | Train Accuracy: 89.750 % | Validation Loss: 0.48053 | Validation Accuracy: 81.798 %\n","Epoch 49: | Train Loss: 0.40772 | Train Accuracy: 90.423 % | Validation Loss: 0.45127 | Validation Accuracy: 85.843 %\n","Epoch 50: | Train Loss: 0.41196 | Train Accuracy: 89.798 % | Validation Loss: 0.43622 | Validation Accuracy: 87.191 %\n","Finished Training ... !!!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IM7RHXrHDCom"},"source":["#### Checking Model Performance"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oGk-eAvC-l_u","executionInfo":{"status":"ok","timestamp":1622188276511,"user_tz":-330,"elapsed":16645,"user":{"displayName":"Abhijeet Upadhyay (MT19AIE201)","photoUrl":"","userId":"12194432948742235723"}},"outputId":"c5299c9f-3995-4fc9-ce10-56aefc06723b"},"source":["#loading best model\n","state_dict = torch.load('/content/drive/MyDrive/MTECH AI/Semester 3/Computer Vision/CV_Project/Saved_Models/cnn_ct_raw_combined.pth')\n","model.load_state_dict(state_dict)\n","\n","#checking model performance on train, validation & test data\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for data in train_loader:\n","        inputs, labels = data[0].to(device), data[1].to(device)      #X & y\n","        inputs = inputs.to(device = device, dtype = torch.float)\n","        outputs = model(inputs)  #prediction\n","        outputs_probs = torch.softmax(outputs, dim = 1)              #predicted probability\n","        _, predicted = torch.max(outputs_probs, 1)                   #assigning class label to prediction\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Accuracy on Train Data: %d %%' % (100 * correct / total))\n","\n","\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for data in val_loader:\n","        inputs, labels = data[0].to(device), data[1].to(device)      #X & y\n","        inputs = inputs.to(device = device, dtype = torch.float)\n","        outputs = model(inputs)  #prediction\n","        outputs_probs = torch.softmax(outputs, dim = 1)              #predicted probability\n","        _, predicted = torch.max(outputs_probs, 1)                   #assigning class label to prediction\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Accuracy on Validation Data: %d %%' % (100 * correct / total))\n","\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for data in test_loader:\n","        inputs, labels = data[0].to(device), data[1].to(device)      #X & y\n","        inputs = inputs.to(device = device, dtype = torch.float)\n","        outputs = model(inputs)  #prediction\n","        outputs_probs = torch.softmax(outputs, dim = 1)              #predicted probability\n","        _, predicted = torch.max(outputs_probs, 1)                   #assigning class label to prediction\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Accuracy on Test Data: %d %%' % (100 * correct / total))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy on Train Data: 93 %\n","Accuracy on Validation Data: 89 %\n","Accuracy on Test Data: 88 %\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ux1o9NNjcQHJ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TwymqodWceNg"},"source":["### 2. Baseline CNN on Combined Data Sources for Training & Testing with Contrast Enhancement"]},{"cell_type":"markdown","metadata":{"id":"zhh-HemIceNg"},"source":["#### Loading Train, Test & Validation Data"]},{"cell_type":"code","metadata":{"id":"5kg7X6eeceNg"},"source":["#data utilitiesa\n","random_state = 100\n","batch_size = 16\n","validation_split = 0.15\n","indices = list(range(data_size_combined))\n","split = int(np.floor(validation_split * data_size_combined))\n","\n","#indices for training and validation splits:\n","np.random.seed(random_state)\n","np.random.shuffle(indices)\n","\n","train_indices, val_indices, test_indices = indices[2*split:], indices[:split], indices[split:2*split]\n","\n","# Creating PT data samplers and loaders:\n","train_sampler = SubsetRandomSampler(train_indices)\n","val_sampler = SubsetRandomSampler(val_indices)\n","test_sampler = SubsetRandomSampler(test_indices)\n","\n","dataset_ = CustomDataset(path = combined_path, enhance = True, enhance_fun = enhance_contrast)\n","train_loader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, sampler = train_sampler, num_workers = 2)\n","val_loader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, sampler = val_sampler, num_workers = 2)\n","test_loader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, sampler = test_sampler, num_workers = 2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O9-YGckeceNh"},"source":["#cnn model class\n","def call_bn(bn, x):\n","    return bn(x)\n","\n","class CNN(nn.Module):\n","    def __init__(self, in_channels = 3):\n","        super(CNN, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels = in_channels, out_channels = 64, kernel_size = 3)\n","        self.conv2 = nn.Conv2d(64, 64, kernel_size = 3)\n","        self.conv3 = nn.Conv2d(64, 96, kernel_size = 3)\n","        self.conv4 = nn.Conv2d(96, 96, kernel_size = 3)\n","        self.conv5 = nn.Conv2d(96, 128, kernel_size = 3)\n","        self.conv6 = nn.Conv2d(128, 128, kernel_size = 3)\n","        self.fc1 = nn.Linear(128 * 5 * 5, 512)\n","        self.fc2 = nn.Linear(512, 64)\n","        self.fc3 = nn.Linear(64, 2)\n","        self.pool = nn.MaxPool2d(kernel_size = 2)\n","        self.dropout = nn.Dropout(0.5)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.bn2 = nn.BatchNorm2d(64)\n","        self.bn3 = nn.BatchNorm2d(96)\n","        self.bn4 = nn.BatchNorm2d(96)\n","        self.bn5 = nn.BatchNorm2d(128)\n","        self.bn6 = nn.BatchNorm2d(128)\n","        self.bn7 = nn.BatchNorm1d(512)\n","        self.bn8 = nn.BatchNorm1d(64)\n","\n","    def forward(self, x, verbose = False):\n","        x = self.conv1(x)\n","        x = call_bn(self.bn1, x)\n","        x = F.relu(x)\n","        x = self.conv2(x)\n","        x = call_bn(self.bn2, x)\n","        x = F.relu(x)\n","        x = self.pool(x)\n","        x = self.dropout(x)\n","\n","        x = self.conv3(x)\n","        x = call_bn(self.bn3, x)\n","        x = F.relu(x)\n","        x = self.pool(x)\n","        x = self.dropout(x)\n","        x = self.conv4(x)\n","        x = call_bn(self.bn4, x)\n","        x = F.relu(x)\n","        x = self.pool(x)\n","        x = self.dropout(x)\n","\n","        x = self.conv5(x)\n","        x = call_bn(self.bn5, x)\n","        x = F.relu(x)\n","        x = self.pool(x)\n","        x = self.dropout(x)\n","        x = self.conv6(x)\n","        x = call_bn(self.bn6, x)\n","        x = F.relu(x)\n","        x = self.pool(x)\n","        x = self.dropout(x)\n","      \n","        x = x.view(-1, 128 * 5 * 5)\n","        \n","        x = self.fc1(x)\n","        x = call_bn(self.bn7, x)\n","        x = F.relu(x)\n","        x = self.dropout(x)\n","        x = self.fc2(x)\n","        x = call_bn(self.bn8, x)\n","        x = F.relu(x)\n","        x = self.dropout(x)\n","        x = self.fc3(x)\n","        \n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SY082_NOceNh","executionInfo":{"status":"ok","timestamp":1622188276513,"user_tz":-330,"elapsed":16,"user":{"displayName":"Abhijeet Upadhyay (MT19AIE201)","photoUrl":"","userId":"12194432948742235723"}},"outputId":"33da9c1c-46d3-4de5-f89d-f252447ef97a"},"source":["#initialise model\n","model = CNN()\n","\n","#set device to be cude\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","#model structure\n","print(model)\n","summary(model, (3, 224, 224))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["CNN(\n","  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n","  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n","  (conv3): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1))\n","  (conv4): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1))\n","  (conv5): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1))\n","  (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n","  (fc1): Linear(in_features=3200, out_features=512, bias=True)\n","  (fc2): Linear(in_features=512, out_features=64, bias=True)\n","  (fc3): Linear(in_features=64, out_features=2, bias=True)\n","  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (bn4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (bn5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (bn6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (bn7): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (bn8): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",")\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 222, 222]           1,792\n","       BatchNorm2d-2         [-1, 64, 222, 222]             128\n","            Conv2d-3         [-1, 64, 220, 220]          36,928\n","       BatchNorm2d-4         [-1, 64, 220, 220]             128\n","         MaxPool2d-5         [-1, 64, 110, 110]               0\n","           Dropout-6         [-1, 64, 110, 110]               0\n","            Conv2d-7         [-1, 96, 108, 108]          55,392\n","       BatchNorm2d-8         [-1, 96, 108, 108]             192\n","         MaxPool2d-9           [-1, 96, 54, 54]               0\n","          Dropout-10           [-1, 96, 54, 54]               0\n","           Conv2d-11           [-1, 96, 52, 52]          83,040\n","      BatchNorm2d-12           [-1, 96, 52, 52]             192\n","        MaxPool2d-13           [-1, 96, 26, 26]               0\n","          Dropout-14           [-1, 96, 26, 26]               0\n","           Conv2d-15          [-1, 128, 24, 24]         110,720\n","      BatchNorm2d-16          [-1, 128, 24, 24]             256\n","        MaxPool2d-17          [-1, 128, 12, 12]               0\n","          Dropout-18          [-1, 128, 12, 12]               0\n","           Conv2d-19          [-1, 128, 10, 10]         147,584\n","      BatchNorm2d-20          [-1, 128, 10, 10]             256\n","        MaxPool2d-21            [-1, 128, 5, 5]               0\n","          Dropout-22            [-1, 128, 5, 5]               0\n","           Linear-23                  [-1, 512]       1,638,912\n","      BatchNorm1d-24                  [-1, 512]           1,024\n","          Dropout-25                  [-1, 512]               0\n","           Linear-26                   [-1, 64]          32,832\n","      BatchNorm1d-27                   [-1, 64]             128\n","          Dropout-28                   [-1, 64]               0\n","           Linear-29                    [-1, 2]             130\n","================================================================\n","Total params: 2,109,634\n","Trainable params: 2,109,634\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 135.18\n","Params size (MB): 8.05\n","Estimated Total Size (MB): 143.80\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3KZ_QW8sceNi"},"source":["#loss & optimizer\n","criterion = nn.CrossEntropyLoss().to(device)\n","optimizer = optim.Adamax(model.parameters(), weight_decay = 1e-6)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dj960lsqceNi","executionInfo":{"status":"ok","timestamp":1622189012027,"user_tz":-330,"elapsed":735525,"user":{"displayName":"Abhijeet Upadhyay (MT19AIE201)","photoUrl":"","userId":"12194432948742235723"}},"outputId":"e4c39907-6400-40ca-989d-3023bb2a58b5"},"source":["#training\n","start_epoch = 0\n","epochs = 50\n","\n","best_val_acc = 0\n","\n","print('Started Training ... !!!')\n","\n","for epoch in range(start_epoch, epochs + start_epoch):\n","\n","    train_loss = 0.0\n","    train_correct = 0.0\n","    items = 0\n","\n","    model.train()\n","    for data in train_loader:\n","        # get the inputs\n","        inputs, labels = data[0], data[1]\n","\n","        items += len(inputs)\n","        \n","        #change inputs to cuda type\n","        inputs = inputs.to(device = device, dtype = torch.float)\n","        labels = labels.to(device = device)\n","\n","        #wrap them in Variable\n","        inputs, labels = Variable(inputs), Variable(labels)\n","\n","        #zero the parameter gradients\n","        optimizer.zero_grad()\n","        \n","        #forward + backward + optimize\n","        pred_train = model(inputs)                                     #prediction\n","        pred_train_probs = torch.softmax(pred_train, dim = 1)          #predicted probability\n","        loss_t = criterion(pred_train_probs, labels)                   #calculate loss\n","        \n","        _, pred_train_labels = torch.max(pred_train_probs, 1)          #assigning class label to prediction\n","        train_correct += (pred_train_labels == labels).sum().item()    #count correct preditions  \n","\n","        loss_t.backward()                                              #backpropogate\n","        optimizer.step()                                               #update weights\n","\n","        train_loss += loss_t.item()                                    #update loss\n","\n","    #normalizing the loss & accuracy by the total number of train batches\n","    train_loss /= len(train_loader)\n","    train_acc =  (train_correct * 100) / items\n","\n","\n","    #MODEL VALIDATION\n","    with torch.no_grad():\n","         model.eval()\n","         val_loss = 0.0\n","         val_correct = 0.0\n","         val_items = 0\n","         \n","         for data_val in val_loader:    #get the inputs\n","             val_inputs, val_labels = data_val[0], data_val[1]\n","\n","             val_items += len(val_inputs)\n","\n","             #converting input and labels to cuda \n","             val_inputs = val_inputs.to(device = device, dtype = torch.float)\n","             val_labels = val_labels.to(device = device)\n","\n","             #wrap them in Variable\n","             val_inputs, val_labels = Variable(val_inputs), Variable(val_labels)\n","\n","             pred_val = model(val_inputs)                                   #prediction\n","             pred_val_probs = torch.softmax(pred_val, dim = 1)              #predicted probability\n","             loss_v = criterion(pred_val_probs, val_labels)                 #calculate loss\n","             \n","             _, pred_val_labels = torch.max(pred_val_probs, 1)              #assigning class label to prediction\n","             val_correct += (pred_val_labels == val_labels).sum().item()    #count correct predictions\n","\n","             val_loss += loss_v.item()                                      #update loss\n","          \n","         #normalizing the loss by the total number of val batches\n","         val_loss /= len(val_loader)\n","         val_acc =  (val_correct * 100) / val_items\n","\n","         #save the best model\n","         if val_acc > best_val_acc:\n","            torch.save(model.state_dict(), '/content/drive/MyDrive/MTECH AI/Semester 3/Computer Vision/CV_Project/Saved_Models/cnn_ct_contrast_combined.pth')   #save model\n","            best_val_acc = val_acc         #change best val accuracy\n","        \n","    print(f'Epoch {epoch + 1}: | Train Loss: {train_loss:.5f} | Train Accuracy: {train_acc:.3f} % | Validation Loss: {val_loss:.5f} | Validation Accuracy: {val_acc:.3f} %')\n","\n","print('Finished Training ... !!!')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Started Training ... !!!\n","Epoch 1: | Train Loss: 0.63489 | Train Accuracy: 65.592 % | Validation Loss: 0.77334 | Validation Accuracy: 52.360 %\n","Epoch 2: | Train Loss: 0.57974 | Train Accuracy: 72.714 % | Validation Loss: 0.62195 | Validation Accuracy: 66.742 %\n","Epoch 3: | Train Loss: 0.53880 | Train Accuracy: 76.756 % | Validation Loss: 0.72378 | Validation Accuracy: 53.258 %\n","Epoch 4: | Train Loss: 0.51759 | Train Accuracy: 79.259 % | Validation Loss: 0.70746 | Validation Accuracy: 53.708 %\n","Epoch 5: | Train Loss: 0.50457 | Train Accuracy: 80.510 % | Validation Loss: 0.68486 | Validation Accuracy: 58.876 %\n","Epoch 6: | Train Loss: 0.49462 | Train Accuracy: 81.809 % | Validation Loss: 0.54987 | Validation Accuracy: 74.157 %\n","Epoch 7: | Train Loss: 0.48355 | Train Accuracy: 82.146 % | Validation Loss: 0.50926 | Validation Accuracy: 79.326 %\n","Epoch 8: | Train Loss: 0.47768 | Train Accuracy: 83.205 % | Validation Loss: 0.65894 | Validation Accuracy: 61.573 %\n","Epoch 9: | Train Loss: 0.48255 | Train Accuracy: 81.906 % | Validation Loss: 0.47597 | Validation Accuracy: 83.820 %\n","Epoch 10: | Train Loss: 0.47566 | Train Accuracy: 82.676 % | Validation Loss: 0.57671 | Validation Accuracy: 71.236 %\n","Epoch 11: | Train Loss: 0.46883 | Train Accuracy: 83.782 % | Validation Loss: 0.50754 | Validation Accuracy: 80.674 %\n","Epoch 12: | Train Loss: 0.46805 | Train Accuracy: 83.542 % | Validation Loss: 0.54297 | Validation Accuracy: 76.404 %\n","Epoch 13: | Train Loss: 0.46487 | Train Accuracy: 84.360 % | Validation Loss: 0.53978 | Validation Accuracy: 74.157 %\n","Epoch 14: | Train Loss: 0.45546 | Train Accuracy: 85.322 % | Validation Loss: 0.44045 | Validation Accuracy: 86.966 %\n","Epoch 15: | Train Loss: 0.44842 | Train Accuracy: 85.804 % | Validation Loss: 0.51307 | Validation Accuracy: 78.202 %\n","Epoch 16: | Train Loss: 0.44558 | Train Accuracy: 86.092 % | Validation Loss: 0.61330 | Validation Accuracy: 68.090 %\n","Epoch 17: | Train Loss: 0.44898 | Train Accuracy: 86.285 % | Validation Loss: 0.54235 | Validation Accuracy: 75.506 %\n","Epoch 18: | Train Loss: 0.44496 | Train Accuracy: 86.044 % | Validation Loss: 0.53985 | Validation Accuracy: 76.180 %\n","Epoch 19: | Train Loss: 0.44534 | Train Accuracy: 85.948 % | Validation Loss: 0.51325 | Validation Accuracy: 78.876 %\n","Epoch 20: | Train Loss: 0.44065 | Train Accuracy: 87.007 % | Validation Loss: 0.47669 | Validation Accuracy: 82.921 %\n","Epoch 21: | Train Loss: 0.44065 | Train Accuracy: 86.670 % | Validation Loss: 0.43679 | Validation Accuracy: 87.416 %\n","Epoch 22: | Train Loss: 0.44446 | Train Accuracy: 85.996 % | Validation Loss: 0.46392 | Validation Accuracy: 84.494 %\n","Epoch 23: | Train Loss: 0.44676 | Train Accuracy: 86.285 % | Validation Loss: 0.49212 | Validation Accuracy: 81.573 %\n","Epoch 24: | Train Loss: 0.43745 | Train Accuracy: 87.344 % | Validation Loss: 0.43927 | Validation Accuracy: 86.292 %\n","Epoch 25: | Train Loss: 0.44099 | Train Accuracy: 86.622 % | Validation Loss: 0.47103 | Validation Accuracy: 84.045 %\n","Epoch 26: | Train Loss: 0.43550 | Train Accuracy: 87.777 % | Validation Loss: 0.41984 | Validation Accuracy: 89.438 %\n","Epoch 27: | Train Loss: 0.42720 | Train Accuracy: 88.162 % | Validation Loss: 0.43247 | Validation Accuracy: 86.742 %\n","Epoch 28: | Train Loss: 0.42990 | Train Accuracy: 87.921 % | Validation Loss: 0.44014 | Validation Accuracy: 86.292 %\n","Epoch 29: | Train Loss: 0.43984 | Train Accuracy: 86.622 % | Validation Loss: 0.42912 | Validation Accuracy: 87.865 %\n","Epoch 30: | Train Loss: 0.42614 | Train Accuracy: 88.065 % | Validation Loss: 0.42303 | Validation Accuracy: 88.539 %\n","Epoch 31: | Train Loss: 0.42268 | Train Accuracy: 88.739 % | Validation Loss: 0.44668 | Validation Accuracy: 86.292 %\n","Epoch 32: | Train Loss: 0.41617 | Train Accuracy: 89.509 % | Validation Loss: 0.42282 | Validation Accuracy: 88.315 %\n","Epoch 33: | Train Loss: 0.42157 | Train Accuracy: 88.884 % | Validation Loss: 0.57157 | Validation Accuracy: 73.483 %\n","Epoch 34: | Train Loss: 0.42334 | Train Accuracy: 88.691 % | Validation Loss: 0.45784 | Validation Accuracy: 84.719 %\n","Epoch 35: | Train Loss: 0.42606 | Train Accuracy: 88.306 % | Validation Loss: 0.45517 | Validation Accuracy: 85.169 %\n","Epoch 36: | Train Loss: 0.42691 | Train Accuracy: 87.921 % | Validation Loss: 0.43892 | Validation Accuracy: 86.517 %\n","Epoch 37: | Train Loss: 0.41108 | Train Accuracy: 89.942 % | Validation Loss: 0.43894 | Validation Accuracy: 86.517 %\n","Epoch 38: | Train Loss: 0.42702 | Train Accuracy: 87.969 % | Validation Loss: 0.52073 | Validation Accuracy: 78.652 %\n","Epoch 39: | Train Loss: 0.41283 | Train Accuracy: 89.750 % | Validation Loss: 0.46930 | Validation Accuracy: 84.045 %\n","Epoch 40: | Train Loss: 0.40971 | Train Accuracy: 90.087 % | Validation Loss: 0.46266 | Validation Accuracy: 84.719 %\n","Epoch 41: | Train Loss: 0.41814 | Train Accuracy: 89.317 % | Validation Loss: 0.45620 | Validation Accuracy: 84.270 %\n","Epoch 42: | Train Loss: 0.41247 | Train Accuracy: 89.798 % | Validation Loss: 0.44267 | Validation Accuracy: 86.966 %\n","Epoch 43: | Train Loss: 0.41666 | Train Accuracy: 89.317 % | Validation Loss: 0.46109 | Validation Accuracy: 85.169 %\n","Epoch 44: | Train Loss: 0.41187 | Train Accuracy: 89.750 % | Validation Loss: 0.46653 | Validation Accuracy: 84.045 %\n","Epoch 45: | Train Loss: 0.39679 | Train Accuracy: 91.386 % | Validation Loss: 0.49785 | Validation Accuracy: 81.124 %\n","Epoch 46: | Train Loss: 0.41376 | Train Accuracy: 89.605 % | Validation Loss: 0.43923 | Validation Accuracy: 87.191 %\n","Epoch 47: | Train Loss: 0.41453 | Train Accuracy: 89.750 % | Validation Loss: 0.42514 | Validation Accuracy: 88.315 %\n","Epoch 48: | Train Loss: 0.41516 | Train Accuracy: 89.557 % | Validation Loss: 0.51838 | Validation Accuracy: 78.202 %\n","Epoch 49: | Train Loss: 0.41658 | Train Accuracy: 89.269 % | Validation Loss: 0.50274 | Validation Accuracy: 80.225 %\n","Epoch 50: | Train Loss: 0.41451 | Train Accuracy: 89.654 % | Validation Loss: 0.41530 | Validation Accuracy: 89.438 %\n","Finished Training ... !!!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HFCTlqBTceNi"},"source":["#### Checking Model Performance"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"By4Ql1xnceNj","executionInfo":{"status":"ok","timestamp":1622189028027,"user_tz":-330,"elapsed":16009,"user":{"displayName":"Abhijeet Upadhyay (MT19AIE201)","photoUrl":"","userId":"12194432948742235723"}},"outputId":"093ac6a6-b459-4ce2-a40a-94444af21e5b"},"source":["#loading best model\n","state_dict = torch.load('/content/drive/MyDrive/MTECH AI/Semester 3/Computer Vision/CV_Project/Saved_Models/cnn_ct_contrast_combined.pth')\n","model.load_state_dict(state_dict)\n","\n","#checking model performance on train, validation & test data\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for data in train_loader:\n","        inputs, labels = data[0].to(device), data[1].to(device)      #X & y\n","        inputs = inputs.to(device = device, dtype = torch.float)\n","        outputs = model(inputs)  #prediction\n","        outputs_probs = torch.softmax(outputs, dim = 1)              #predicted probability\n","        _, predicted = torch.max(outputs_probs, 1)                   #assigning class label to prediction\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Accuracy on Train Data: %d %%' % (100 * correct / total))\n","\n","\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for data in val_loader:\n","        inputs, labels = data[0].to(device), data[1].to(device)      #X & y\n","        inputs = inputs.to(device = device, dtype = torch.float)\n","        outputs = model(inputs)  #prediction\n","        outputs_probs = torch.softmax(outputs, dim = 1)              #predicted probability\n","        _, predicted = torch.max(outputs_probs, 1)                   #assigning class label to prediction\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Accuracy on Validation Data: %d %%' % (100 * correct / total))\n","\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for data in test_loader:\n","        inputs, labels = data[0].to(device), data[1].to(device)      #X & y\n","        inputs = inputs.to(device = device, dtype = torch.float)\n","        outputs = model(inputs)  #prediction\n","        outputs_probs = torch.softmax(outputs, dim = 1)              #predicted probability\n","        _, predicted = torch.max(outputs_probs, 1)                   #assigning class label to prediction\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Accuracy on Test Data: %d %%' % (100 * correct / total))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy on Train Data: 92 %\n","Accuracy on Validation Data: 89 %\n","Accuracy on Test Data: 90 %\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rcxR03XrMs7o"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZrO1Az3ES1xh"},"source":["### 3. Baseline CNN on Combined Data Sources for Training & Testing with Brightness Enhancement"]},{"cell_type":"markdown","metadata":{"id":"a5x6Zz9LS1xl"},"source":["#### Loading Train, Test & Validation Data"]},{"cell_type":"code","metadata":{"id":"P-g93cPtS1xm"},"source":["#data utilitiesa\n","random_state = 100\n","batch_size = 16\n","validation_split = 0.15\n","indices = list(range(data_size_combined))\n","split = int(np.floor(validation_split * data_size_combined))\n","\n","#indices for training and validation splits:\n","np.random.seed(random_state)\n","np.random.shuffle(indices)\n","\n","train_indices, val_indices, test_indices = indices[2*split:], indices[:split], indices[split:2*split]\n","\n","# Creating PT data samplers and loaders:\n","train_sampler = SubsetRandomSampler(train_indices)\n","val_sampler = SubsetRandomSampler(val_indices)\n","test_sampler = SubsetRandomSampler(test_indices)\n","\n","dataset = CustomDataset(path = combined_path, enhance = True, enhance_fun = enhance_brightness)\n","train_loader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, sampler = train_sampler, num_workers = 2)\n","val_loader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, sampler = val_sampler, num_workers = 2)\n","test_loader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, sampler = test_sampler, num_workers = 2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eE601BXoS1xn"},"source":["#cnn model class\n","def call_bn(bn, x):\n","    return bn(x)\n","\n","class CNN(nn.Module):\n","    def __init__(self, in_channels = 3):\n","        super(CNN, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels = in_channels, out_channels = 64, kernel_size = 3)\n","        self.conv2 = nn.Conv2d(64, 64, kernel_size = 3)\n","        self.conv3 = nn.Conv2d(64, 96, kernel_size = 3)\n","        self.conv4 = nn.Conv2d(96, 96, kernel_size = 3)\n","        self.conv5 = nn.Conv2d(96, 128, kernel_size = 3)\n","        self.conv6 = nn.Conv2d(128, 128, kernel_size = 3)\n","        self.fc1 = nn.Linear(128 * 5 * 5, 512)\n","        self.fc2 = nn.Linear(512, 64)\n","        self.fc3 = nn.Linear(64, 2)\n","        self.pool = nn.MaxPool2d(kernel_size = 2)\n","        self.dropout = nn.Dropout(0.5)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.bn2 = nn.BatchNorm2d(64)\n","        self.bn3 = nn.BatchNorm2d(96)\n","        self.bn4 = nn.BatchNorm2d(96)\n","        self.bn5 = nn.BatchNorm2d(128)\n","        self.bn6 = nn.BatchNorm2d(128)\n","        self.bn7 = nn.BatchNorm1d(512)\n","        self.bn8 = nn.BatchNorm1d(64)\n","\n","    def forward(self, x, verbose = False):\n","        x = self.conv1(x)\n","        x = call_bn(self.bn1, x)\n","        x = F.relu(x)\n","        x = self.conv2(x)\n","        x = call_bn(self.bn2, x)\n","        x = F.relu(x)\n","        x = self.pool(x)\n","        x = self.dropout(x)\n","\n","        x = self.conv3(x)\n","        x = call_bn(self.bn3, x)\n","        x = F.relu(x)\n","        x = self.pool(x)\n","        x = self.dropout(x)\n","        x = self.conv4(x)\n","        x = call_bn(self.bn4, x)\n","        x = F.relu(x)\n","        x = self.pool(x)\n","        x = self.dropout(x)\n","\n","        x = self.conv5(x)\n","        x = call_bn(self.bn5, x)\n","        x = F.relu(x)\n","        x = self.pool(x)\n","        x = self.dropout(x)\n","        x = self.conv6(x)\n","        x = call_bn(self.bn6, x)\n","        x = F.relu(x)\n","        x = self.pool(x)\n","        x = self.dropout(x)\n","      \n","        x = x.view(-1, 128 * 5 * 5)\n","        \n","        x = self.fc1(x)\n","        x = call_bn(self.bn7, x)\n","        x = F.relu(x)\n","        x = self.dropout(x)\n","        x = self.fc2(x)\n","        x = call_bn(self.bn8, x)\n","        x = F.relu(x)\n","        x = self.dropout(x)\n","        x = self.fc3(x)\n","        \n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PbV009poS1xn","executionInfo":{"status":"ok","timestamp":1622189028030,"user_tz":-330,"elapsed":15,"user":{"displayName":"Abhijeet Upadhyay (MT19AIE201)","photoUrl":"","userId":"12194432948742235723"}},"outputId":"417b3108-216d-4fad-862e-e4ecd7d65e94"},"source":["#initialise model\n","model = CNN()\n","\n","#set device to be cude\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","#model structure\n","print(model)\n","summary(model, (3, 224, 224))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["CNN(\n","  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n","  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n","  (conv3): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1))\n","  (conv4): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1))\n","  (conv5): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1))\n","  (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n","  (fc1): Linear(in_features=3200, out_features=512, bias=True)\n","  (fc2): Linear(in_features=512, out_features=64, bias=True)\n","  (fc3): Linear(in_features=64, out_features=2, bias=True)\n","  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (bn4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (bn5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (bn6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (bn7): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (bn8): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",")\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 222, 222]           1,792\n","       BatchNorm2d-2         [-1, 64, 222, 222]             128\n","            Conv2d-3         [-1, 64, 220, 220]          36,928\n","       BatchNorm2d-4         [-1, 64, 220, 220]             128\n","         MaxPool2d-5         [-1, 64, 110, 110]               0\n","           Dropout-6         [-1, 64, 110, 110]               0\n","            Conv2d-7         [-1, 96, 108, 108]          55,392\n","       BatchNorm2d-8         [-1, 96, 108, 108]             192\n","         MaxPool2d-9           [-1, 96, 54, 54]               0\n","          Dropout-10           [-1, 96, 54, 54]               0\n","           Conv2d-11           [-1, 96, 52, 52]          83,040\n","      BatchNorm2d-12           [-1, 96, 52, 52]             192\n","        MaxPool2d-13           [-1, 96, 26, 26]               0\n","          Dropout-14           [-1, 96, 26, 26]               0\n","           Conv2d-15          [-1, 128, 24, 24]         110,720\n","      BatchNorm2d-16          [-1, 128, 24, 24]             256\n","        MaxPool2d-17          [-1, 128, 12, 12]               0\n","          Dropout-18          [-1, 128, 12, 12]               0\n","           Conv2d-19          [-1, 128, 10, 10]         147,584\n","      BatchNorm2d-20          [-1, 128, 10, 10]             256\n","        MaxPool2d-21            [-1, 128, 5, 5]               0\n","          Dropout-22            [-1, 128, 5, 5]               0\n","           Linear-23                  [-1, 512]       1,638,912\n","      BatchNorm1d-24                  [-1, 512]           1,024\n","          Dropout-25                  [-1, 512]               0\n","           Linear-26                   [-1, 64]          32,832\n","      BatchNorm1d-27                   [-1, 64]             128\n","          Dropout-28                   [-1, 64]               0\n","           Linear-29                    [-1, 2]             130\n","================================================================\n","Total params: 2,109,634\n","Trainable params: 2,109,634\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 135.18\n","Params size (MB): 8.05\n","Estimated Total Size (MB): 143.80\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"10x75dYKS1xo"},"source":["#loss & optimizer\n","criterion = nn.CrossEntropyLoss().to(device)\n","optimizer = optim.Adamax(model.parameters(), weight_decay = 1e-6)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2gDRm5QuS1xp","executionInfo":{"status":"ok","timestamp":1622189896539,"user_tz":-330,"elapsed":868521,"user":{"displayName":"Abhijeet Upadhyay (MT19AIE201)","photoUrl":"","userId":"12194432948742235723"}},"outputId":"1a9ffb41-6fa3-45b6-a6f6-c08b9f75be90"},"source":["#training\n","start_epoch = 0\n","epochs = 50\n","\n","best_val_acc = 0\n","\n","print('Started Training ... !!!')\n","\n","for epoch in range(start_epoch, epochs + start_epoch):\n","\n","    train_loss = 0.0\n","    train_correct = 0.0\n","    items = 0\n","\n","    model.train()\n","    for data in train_loader:\n","        # get the inputs\n","        inputs, labels = data[0], data[1]\n","\n","        items += len(inputs)\n","        \n","        #change inputs to cuda type\n","        inputs = inputs.to(device = device, dtype = torch.float)\n","        labels = labels.to(device = device)\n","\n","        #wrap them in Variable\n","        inputs, labels = Variable(inputs), Variable(labels)\n","\n","        #zero the parameter gradients\n","        optimizer.zero_grad()\n","        \n","        #forward + backward + optimize\n","        pred_train = model(inputs)                                     #prediction\n","        pred_train_probs = torch.softmax(pred_train, dim = 1)          #predicted probability\n","        loss_t = criterion(pred_train_probs, labels)                   #calculate loss\n","        \n","        _, pred_train_labels = torch.max(pred_train_probs, 1)          #assigning class label to prediction\n","        train_correct += (pred_train_labels == labels).sum().item()    #count correct preditions  \n","\n","        loss_t.backward()                                              #backpropogate\n","        optimizer.step()                                               #update weights\n","\n","        train_loss += loss_t.item()                                    #update loss\n","\n","    #normalizing the loss & accuracy by the total number of train batches\n","    train_loss /= len(train_loader)\n","    train_acc =  (train_correct * 100) / items\n","\n","\n","    #MODEL VALIDATION\n","    with torch.no_grad():\n","         model.eval()\n","         val_loss = 0.0\n","         val_correct = 0.0\n","         val_items = 0\n","         \n","         for data_val in val_loader:    #get the inputs\n","             val_inputs, val_labels = data_val[0], data_val[1]\n","\n","             val_items += len(val_inputs)\n","\n","             #converting input and labels to cuda \n","             val_inputs = val_inputs.to(device = device, dtype = torch.float)\n","             val_labels = val_labels.to(device = device)\n","\n","             #wrap them in Variable\n","             val_inputs, val_labels = Variable(val_inputs), Variable(val_labels)\n","\n","             pred_val = model(val_inputs)                                   #prediction\n","             pred_val_probs = torch.softmax(pred_val, dim = 1)              #predicted probability\n","             loss_v = criterion(pred_val_probs, val_labels)                 #calculate loss\n","             \n","             _, pred_val_labels = torch.max(pred_val_probs, 1)              #assigning class label to prediction\n","             val_correct += (pred_val_labels == val_labels).sum().item()    #count correct predictions\n","\n","             val_loss += loss_v.item()                                      #update loss\n","          \n","         #normalizing the loss by the total number of val batches\n","         val_loss /= len(val_loader)\n","         val_acc =  (val_correct * 100) / val_items\n","\n","         #save the best model\n","         if val_acc > best_val_acc:\n","            torch.save(model.state_dict(), '/content/drive/MyDrive/MTECH AI/Semester 3/Computer Vision/CV_Project/Saved_Models/cnn_ct_brightness_combined.pth')   #save model\n","            best_val_acc = val_acc         #change best val accuracy\n","        \n","    print(f'Epoch {epoch + 1}: | Train Loss: {train_loss:.5f} | Train Accuracy: {train_acc:.3f} % | Validation Loss: {val_loss:.5f} | Validation Accuracy: {val_acc:.3f} %')\n","\n","print('Finished Training ... !!!')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Started Training ... !!!\n","Epoch 1: | Train Loss: 0.61102 | Train Accuracy: 68.961 % | Validation Loss: 0.74022 | Validation Accuracy: 51.910 %\n","Epoch 2: | Train Loss: 0.54183 | Train Accuracy: 77.575 % | Validation Loss: 0.73737 | Validation Accuracy: 53.933 %\n","Epoch 3: | Train Loss: 0.51352 | Train Accuracy: 79.403 % | Validation Loss: 0.77028 | Validation Accuracy: 51.910 %\n","Epoch 4: | Train Loss: 0.51050 | Train Accuracy: 79.885 % | Validation Loss: 0.66781 | Validation Accuracy: 62.472 %\n","Epoch 5: | Train Loss: 0.50256 | Train Accuracy: 79.885 % | Validation Loss: 0.64675 | Validation Accuracy: 63.596 %\n","Epoch 6: | Train Loss: 0.50014 | Train Accuracy: 80.366 % | Validation Loss: 0.65236 | Validation Accuracy: 64.494 %\n","Epoch 7: | Train Loss: 0.48454 | Train Accuracy: 82.483 % | Validation Loss: 0.71841 | Validation Accuracy: 57.079 %\n","Epoch 8: | Train Loss: 0.48320 | Train Accuracy: 82.243 % | Validation Loss: 0.58821 | Validation Accuracy: 71.011 %\n","Epoch 9: | Train Loss: 0.48256 | Train Accuracy: 82.098 % | Validation Loss: 0.66534 | Validation Accuracy: 63.146 %\n","Epoch 10: | Train Loss: 0.46913 | Train Accuracy: 84.312 % | Validation Loss: 0.62071 | Validation Accuracy: 66.517 %\n","Epoch 11: | Train Loss: 0.46721 | Train Accuracy: 83.782 % | Validation Loss: 0.67977 | Validation Accuracy: 62.247 %\n","Epoch 12: | Train Loss: 0.46886 | Train Accuracy: 83.734 % | Validation Loss: 0.65396 | Validation Accuracy: 64.270 %\n","Epoch 13: | Train Loss: 0.46697 | Train Accuracy: 83.831 % | Validation Loss: 0.60655 | Validation Accuracy: 68.539 %\n","Epoch 14: | Train Loss: 0.46498 | Train Accuracy: 84.601 % | Validation Loss: 0.62648 | Validation Accuracy: 66.742 %\n","Epoch 15: | Train Loss: 0.45515 | Train Accuracy: 85.178 % | Validation Loss: 0.54670 | Validation Accuracy: 74.831 %\n","Epoch 16: | Train Loss: 0.45896 | Train Accuracy: 85.130 % | Validation Loss: 0.64949 | Validation Accuracy: 65.169 %\n","Epoch 17: | Train Loss: 0.45370 | Train Accuracy: 85.419 % | Validation Loss: 0.46550 | Validation Accuracy: 83.820 %\n","Epoch 18: | Train Loss: 0.46020 | Train Accuracy: 84.937 % | Validation Loss: 0.51035 | Validation Accuracy: 79.775 %\n","Epoch 19: | Train Loss: 0.44768 | Train Accuracy: 85.852 % | Validation Loss: 0.57082 | Validation Accuracy: 72.360 %\n","Epoch 20: | Train Loss: 0.44867 | Train Accuracy: 85.852 % | Validation Loss: 0.56761 | Validation Accuracy: 73.258 %\n","Epoch 21: | Train Loss: 0.43982 | Train Accuracy: 86.429 % | Validation Loss: 0.53528 | Validation Accuracy: 76.854 %\n","Epoch 22: | Train Loss: 0.44436 | Train Accuracy: 86.141 % | Validation Loss: 0.58337 | Validation Accuracy: 71.685 %\n","Epoch 23: | Train Loss: 0.43666 | Train Accuracy: 87.825 % | Validation Loss: 0.47450 | Validation Accuracy: 83.596 %\n","Epoch 24: | Train Loss: 0.44473 | Train Accuracy: 86.574 % | Validation Loss: 0.46977 | Validation Accuracy: 83.371 %\n","Epoch 25: | Train Loss: 0.44618 | Train Accuracy: 86.285 % | Validation Loss: 0.52947 | Validation Accuracy: 77.303 %\n","Epoch 26: | Train Loss: 0.43286 | Train Accuracy: 87.729 % | Validation Loss: 0.49746 | Validation Accuracy: 81.348 %\n","Epoch 27: | Train Loss: 0.42656 | Train Accuracy: 88.787 % | Validation Loss: 0.53715 | Validation Accuracy: 75.730 %\n","Epoch 28: | Train Loss: 0.43769 | Train Accuracy: 87.440 % | Validation Loss: 0.49876 | Validation Accuracy: 80.449 %\n","Epoch 29: | Train Loss: 0.43359 | Train Accuracy: 87.777 % | Validation Loss: 0.59585 | Validation Accuracy: 70.562 %\n","Epoch 30: | Train Loss: 0.43648 | Train Accuracy: 87.392 % | Validation Loss: 0.49155 | Validation Accuracy: 81.573 %\n","Epoch 31: | Train Loss: 0.42682 | Train Accuracy: 88.114 % | Validation Loss: 0.49764 | Validation Accuracy: 81.124 %\n","Epoch 32: | Train Loss: 0.43344 | Train Accuracy: 87.632 % | Validation Loss: 0.43705 | Validation Accuracy: 86.742 %\n","Epoch 33: | Train Loss: 0.41825 | Train Accuracy: 89.413 % | Validation Loss: 0.44128 | Validation Accuracy: 86.517 %\n","Epoch 34: | Train Loss: 0.41259 | Train Accuracy: 89.750 % | Validation Loss: 0.46961 | Validation Accuracy: 83.146 %\n","Epoch 35: | Train Loss: 0.42170 | Train Accuracy: 88.932 % | Validation Loss: 0.44294 | Validation Accuracy: 87.191 %\n","Epoch 36: | Train Loss: 0.42575 | Train Accuracy: 88.114 % | Validation Loss: 0.45734 | Validation Accuracy: 84.270 %\n","Epoch 37: | Train Loss: 0.42543 | Train Accuracy: 88.402 % | Validation Loss: 0.57386 | Validation Accuracy: 73.483 %\n","Epoch 38: | Train Loss: 0.41321 | Train Accuracy: 89.846 % | Validation Loss: 0.52674 | Validation Accuracy: 77.978 %\n","Epoch 39: | Train Loss: 0.41999 | Train Accuracy: 88.932 % | Validation Loss: 0.48637 | Validation Accuracy: 82.022 %\n","Epoch 40: | Train Loss: 0.41464 | Train Accuracy: 89.990 % | Validation Loss: 0.45293 | Validation Accuracy: 85.393 %\n","Epoch 41: | Train Loss: 0.40863 | Train Accuracy: 90.327 % | Validation Loss: 0.43630 | Validation Accuracy: 86.966 %\n","Epoch 42: | Train Loss: 0.42433 | Train Accuracy: 88.306 % | Validation Loss: 0.46197 | Validation Accuracy: 84.045 %\n","Epoch 43: | Train Loss: 0.41531 | Train Accuracy: 89.269 % | Validation Loss: 0.47317 | Validation Accuracy: 83.371 %\n","Epoch 44: | Train Loss: 0.42554 | Train Accuracy: 88.162 % | Validation Loss: 0.45545 | Validation Accuracy: 84.719 %\n","Epoch 45: | Train Loss: 0.41793 | Train Accuracy: 88.835 % | Validation Loss: 0.51976 | Validation Accuracy: 78.427 %\n","Epoch 46: | Train Loss: 0.40686 | Train Accuracy: 90.664 % | Validation Loss: 0.48227 | Validation Accuracy: 82.022 %\n","Epoch 47: | Train Loss: 0.41510 | Train Accuracy: 89.605 % | Validation Loss: 0.50568 | Validation Accuracy: 80.225 %\n","Epoch 48: | Train Loss: 0.40191 | Train Accuracy: 90.857 % | Validation Loss: 0.41211 | Validation Accuracy: 90.112 %\n","Epoch 49: | Train Loss: 0.40243 | Train Accuracy: 90.857 % | Validation Loss: 0.44347 | Validation Accuracy: 87.416 %\n","Epoch 50: | Train Loss: 0.40648 | Train Accuracy: 90.375 % | Validation Loss: 0.49757 | Validation Accuracy: 80.899 %\n","Finished Training ... !!!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8Lx81xx1S1xp"},"source":["#### Checking Model Performance"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hwV-fh6wS1xq","executionInfo":{"status":"ok","timestamp":1622189915687,"user_tz":-330,"elapsed":19157,"user":{"displayName":"Abhijeet Upadhyay (MT19AIE201)","photoUrl":"","userId":"12194432948742235723"}},"outputId":"f4413dd2-9761-4374-904f-b983744e963e"},"source":["#loading best model\n","state_dict = torch.load('/content/drive/MyDrive/MTECH AI/Semester 3/Computer Vision/CV_Project/Saved_Models/cnn_ct_brightness_combined.pth')\n","model.load_state_dict(state_dict)\n","\n","#checking model performance on train, validation & test data\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for data in train_loader:\n","        inputs, labels = data[0].to(device), data[1].to(device)      #X & y\n","        inputs = inputs.to(device = device, dtype = torch.float)\n","        outputs = model(inputs)  #prediction\n","        outputs_probs = torch.softmax(outputs, dim = 1)              #predicted probability\n","        _, predicted = torch.max(outputs_probs, 1)                   #assigning class label to prediction\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Accuracy on Train Data: %d %%' % (100 * correct / total))\n","\n","\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for data in val_loader:\n","        inputs, labels = data[0].to(device), data[1].to(device)      #X & y\n","        inputs = inputs.to(device = device, dtype = torch.float)\n","        outputs = model(inputs)  #prediction\n","        outputs_probs = torch.softmax(outputs, dim = 1)              #predicted probability\n","        _, predicted = torch.max(outputs_probs, 1)                   #assigning class label to prediction\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Accuracy on Validation Data: %d %%' % (100 * correct / total))\n","\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for data in test_loader:\n","        inputs, labels = data[0].to(device), data[1].to(device)      #X & y\n","        inputs = inputs.to(device = device, dtype = torch.float)\n","        outputs = model(inputs)  #prediction\n","        outputs_probs = torch.softmax(outputs, dim = 1)              #predicted probability\n","        _, predicted = torch.max(outputs_probs, 1)                   #assigning class label to prediction\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Accuracy on Test Data: %d %%' % (100 * correct / total))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy on Train Data: 92 %\n","Accuracy on Validation Data: 90 %\n","Accuracy on Test Data: 89 %\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7CYsWrLTcGmc"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"geNGrTbY0GiG"},"source":["Combining both the data set yields better result."]},{"cell_type":"code","metadata":{"id":"GoNRiRQM0Ky4"},"source":[""],"execution_count":null,"outputs":[]}]}